A repo for me to explore how the fuck GPT actually works. This is the pretrain step, meaning I'm training everything from scratch, in this example with the TinyShakespeare dataset.
Required libs: PyTorch (preferrably with GPU if possible), tqdm (for progress bar loading)
